<!DOCTYPE HTML>
<html lang="english">

<head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="renderer" content="webkit">
    <meta name="HandheldFriendly" content="true">
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
    <meta name="keywords" content="Maverick,AlanDecode,Galileo,blog" />
    <meta name="generator" content="Maverick 1.2.1" />
    <meta name="template" content="Prism" />
    <link rel="alternate" type="application/rss+xml" title="walker's code blog &raquo; RSS 2.0" href="/feed/index.xml" />
    <link rel="alternate" type="application/atom+xml" title="walker's code blog &raquo; ATOM 1.0" href="/feed/atom/index.xml" />
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/wzywalker/wzywalker.github.io@main/assets/prism-b9d78ff38a.css">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/wzywalker/wzywalker.github.io@main/assets/ExSearch/ExSearch-182e5a8869.css">
    <link href="https://fonts.googleapis.com/css?family=Fira+Code&display=swap" rel="stylesheet">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/font-awesome@4.7.0/css/font-awesome.min.css">
    <script>
        var ExSearchConfig = {
            root: "",
            api: "https://cdn.jsdelivr.net/gh/wzywalker/wzywalker.github.io@main/e83a979bdfe76b3eb88998ea61cf43ad.json"
        }

    </script>
    
<title>《Deep Learning with Python》笔记[1] - walker's code blog</title>
<meta name="author" content="walker" />
<meta name="description" content="本来是打算趁这个时间好好看看花书的，前几章看下来确实觉得获益匪浅，但看下去就发现跟不上了，特别是抱着急功近利的心态的话，目前也沉不下去真的一节节吃透地往下看。这类书终归不是入门教材，是需要你有过一定的积累后再回过头来看的。于是想到了《Deep Learning with Python》，忘记这本书怎么来的了，但是在别的地方看到了有人推荐，说是Keras的作者写的非常好的一本入门书，翻了前面几十页后发现居然跟进去了，不该讲的地方没讲比如数学细节，而且思路也极其统一，从头贯穿到尾（比如representations, latent space,  hypothesis space），我觉得很受用。三百多页全英文，居然也没查几个单词就这么看完了，以前看文档最多十来页，也算一个突破了，可见其实还是一个耐心的问题。看完后书上做了很多笔记，于是顺着笔记读了第二遍，顺便就把笔记给电子化了。不是教程，不是导读。Fundamentals of deep learning" />
<meta property="og:title" content="《Deep Learning with Python》笔记[1] - walker's code blog" />
<meta property="og:description" content="本来是打算趁这个时间好好看看花书的，前几章看下来确实觉得获益匪浅，但看下去就发现跟不上了，特别是抱着急功近利的心态的话，目前也沉不下去真的一节节吃透地往下看。这类书终归不是入门教材，是需要你有过一定的积累后再回过头来看的。于是想到了《Deep Learning with Python》，忘记这本书怎么来的了，但是在别的地方看到了有人推荐，说是Keras的作者写的非常好的一本入门书，翻了前面几十页后发现居然跟进去了，不该讲的地方没讲比如数学细节，而且思路也极其统一，从头贯穿到尾（比如representations, latent space,  hypothesis space），我觉得很受用。三百多页全英文，居然也没查几个单词就这么看完了，以前看文档最多十来页，也算一个突破了，可见其实还是一个耐心的问题。看完后书上做了很多笔记，于是顺着笔记读了第二遍，顺便就把笔记给电子化了。不是教程，不是导读。Fundamentals of deep learning" />
<meta property="og:site_name" content="walker's code blog" />
<meta property="og:type" content="article" />
<meta property="og:url" content="/archives/Deep-Learning-with-Python-Notes-1/" />
<meta property="og:image" content="" />
<meta property="article:published_time" content="2021-09-12T00:00:00-00.00" />
<meta name="twitter:title" content="《Deep Learning with Python》笔记[1] - walker's code blog" />
<meta name="twitter:description" content="本来是打算趁这个时间好好看看花书的，前几章看下来确实觉得获益匪浅，但看下去就发现跟不上了，特别是抱着急功近利的心态的话，目前也沉不下去真的一节节吃透地往下看。这类书终归不是入门教材，是需要你有过一定的积累后再回过头来看的。于是想到了《Deep Learning with Python》，忘记这本书怎么来的了，但是在别的地方看到了有人推荐，说是Keras的作者写的非常好的一本入门书，翻了前面几十页后发现居然跟进去了，不该讲的地方没讲比如数学细节，而且思路也极其统一，从头贯穿到尾（比如representations, latent space,  hypothesis space），我觉得很受用。三百多页全英文，居然也没查几个单词就这么看完了，以前看文档最多十来页，也算一个突破了，可见其实还是一个耐心的问题。看完后书上做了很多笔记，于是顺着笔记读了第二遍，顺便就把笔记给电子化了。不是教程，不是导读。Fundamentals of deep learning" />
<meta name="twitter:card" content="summary" />
<meta name="twitter:image" content="" />


    
</head>

<body>
    <div class="container prism-container">
        <header class="prism-header" id="prism__header">
            <h1 class="text-uppercase brand"><a class="no-link" href="/" target="_self">walker's code blog</a></h1>
            <p>coder, reader</p>
            <nav class="prism-nav"><ul><li><a class="no-link text-uppercase " href="/" target="_self">Home</a></li><li><a class="no-link text-uppercase " href="/archives/" target="_self">Archives</a></li><li><a class="no-link text-uppercase " href="/about/" target="_self">About</a></li><li><a href="#" target="_self" class="search-form-input no-link text-uppercase">Search</a></li></ul></nav>
        </header>
        <div class="prism-wrapper" id="prism__wrapper">
            
<main>
    <section class="prism-section row" id="prism__content">
        <article class="yue col-md-8 offset-md-2">
            <h1 class="prism-post-title">《Deep Learning with Python》笔记[1]</h1>
            <div class="prism-post-time">
                <time class="text-uppercase">
                    September 12 2021
                </time>
            </div>
            <div class="prism-content-body">
                <p>本来是打算趁这个时间好好看看花书的，前几章看下来确实觉得获益匪浅，但看下去就发现跟不上了，特别是抱着急功近利的心态的话，目前也沉不下去真的一节节吃透地往下看。这类书终归不是入门教材，是需要你有过一定的积累后再回过头来看的。</p><p>于是想到了《Deep Learning with Python》，忘记这本书怎么来的了，但是在别的地方看到了有人推荐，说是Keras的作者写的非常好的一本入门书，翻了前面几十页后发现居然跟进去了，不该讲的地方没讲比如数学细节，而且思路也极其统一，从头贯穿到尾（比如representations, latent space,  hypothesis space），我觉得很受用。</p><p>三百多页全英文，居然也没查几个单词就这么看完了，以前看文档最多十来页，也算一个突破了，可见其实还是一个耐心的问题。</p><p>看完后书上做了很多笔记，于是顺着笔记读了第二遍，顺便就把笔记给电子化了。不是教程，不是导读。</p><h1>Fundamentals of deep learning</h1>
<p><strong>核心思想</strong>：
learng useful <code>representations</code> of input data</p><blockquote>
<p>what’s a <code>representation</code>?</p><p>At its core, it’s a different way to look at data—to represent or encode data.</p></blockquote>
<p>简单回顾深度学习之于人工智能的历史，每本书都会写，但每本书里都有作者自己的侧重：</p><ul>
<li>Artificial intelligence</li>
<li>Machine learning<ul>
<li>Machine learning is tightly related to <code>mathematical statistics</code>, but it differs from statistics in several important ways.<ul>
<li>machine learning tends to deal with large, complex datasets (such as a dataset of millions of images, each consisting of tens of thousands of pixels)</li>
<li>classical statistical analysis such as Bayesian analysis would be impractical(不切实际的).</li>
<li>It’s a hands-on discipline in which ideas are proven empirically more often than theoretically.（工程/实践大于理论）</li>
</ul>
</li>
<li>是一种meaningfully transform data<ul>
<li>Machine-learning models are all about finding appropriate representations for their input data—transformations of the data that make it more amenable to the task at hand, such as a classification task.</li>
<li>寻找更有代表性的representation, 通过:(coordinate change, linear projections, tranlsations, nonlinear operations)</li>
<li>只会在<code>hypothesis space</code>里寻找</li>
<li>以某种反馈为信号作为优化指导</li>
</ul>
</li>
</ul>
</li>
<li>Deep learning<ul>
<li>Machine Learing的子集，一种新的learning representation的新方法</li>
<li>虽然叫神经网络(<code>neural network</code>)，但它既非neural，也不是network，更合理的名字：<ul>
<li><code>layered representations learning</code> and <code>hierarchical representations learning</code>.</li>
</ul>
</li>
<li>相对少的层数的实现叫<code>shallow learning</code></li>
</ul>
</li>
</ul>
<h2>Before deep learning</h2>
<ul>
<li>Probabilistic modeling<ul>
<li>the earliest forms of machine learning,</li>
<li>still widely used to this day.<ul>
<li>One of the best-known algorithms in this category</li>
</ul>
</li>
</ul>
</li>
</ul>
<p>is the <code>Naive Bayes algorithm</code>(朴素贝叶斯)
    * 条件概率，把规则理解为“条件”，判断概率，比如垃圾邮件。
        * A closely related model is the logistic regression</p><ul>
<li>Early neural networks<ul>
<li>in the mid-1980s, multiple people independently rediscovered the Backpropagation algorithm</li>
<li>The <code>first</code> successful practical application of neural nets came in 1989 from Bell Labs -&gt; <strong>LeNet</strong></li>
</ul>
</li>
<li>Kernel methods<ul>
<li>Kernel methods are <code>a group of classification algorithms</code>(核方法是一组分类算法)<ul>
<li>the best known of which is the <code>support vector machine</code> (<strong>SVM</strong>).</li>
<li>SVMs aim at solving classification problems <strong>by</strong> finding good <em>decision boundaries</em> between two sets of points belonging to two different categories.<ol>
<li>先把数据映射到高维，decision boundary表示为<code>hyperplane</code></li>
<li>最大化每个类别里离hyperplane最近的点到hyperplane的距离:<code>maximizing the margin</code></li>
</ol>
</li>
<li>The technique of mapping data to a high-dimensional representation 非常消耗计算资源，实际使用的是核函数(<code>kernel function</code>):<ul>
<li>不把每个点转换到高维，而只是计算每两个点在高维中的距离</li>
<li>核函数是手工设计的，不是学习的</li>
</ul>
</li>
<li>SVM在分类问题上是经典方案，但难以扩展到大型数据集上</li>
<li>对于perceptual problems(感知类的问题)如图像分类效果也不好<ul>
<li>它是一个<code>shallow method</code></li>
<li>需要事先手动提取有用特征(<code>feature enginerring</code>)-&gt; difficult and  brittle（脆弱的）</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>Decision trees, random forests, and gradient boosting machines<ul>
<li>Random Forest<ul>
<li>you could say that they’re almost always the <em>second-best</em> algorithm for any shallow machine-learning task.</li>
</ul>
</li>
<li>gradient boosting machines (1st):<ul>
<li>a way to improve any machine-learning model by iteratively training new models that specialize in <code>addressing the weak points of the previous models</code>.</li>
</ul>
</li>
</ul>
</li>
</ul>
<h2>What makes deep learning different</h2>
<p>it completely automates what <em>used to be</em> <strong>the most crucial step</strong> in a machine-learning workflow: <code>feature engineering</code>. 有人认为这叫穷举，思路上有点像，至少得到特征的过程不是靠观察和分析。</p><p><strong>feature engineering</strong></p><blockquote>
<p>manually engineer good layers of representations for their data</p></blockquote>

            </div>
        </article>
        <div class="prism-post-meta col-md-8 offset-md-2">
    <span>walker</span>
    
    <span>/</span>
    <span>
        <a class="category no-link" href="/category/posts/" target="_self">
        posts
        </a>
    </span>
    
    
    <span>/</span>
    
    <span class="prism-tag">
        <a class="no-link" href="/tag/deep%20learning/" target="_self">#deep learning</a>
    </span>
    
    <span class="prism-tag">
        <a class="no-link" href="/tag/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/" target="_self">#深度学习</a>
    </span>
    
    <span class="prism-tag">
        <a class="no-link" href="/tag/keras/" target="_self">#keras</a>
    </span>
    
    <span class="prism-tag">
        <a class="no-link" href="/tag/cv/" target="_self">#cv</a>
    </span>
    
    <span class="prism-tag">
        <a class="no-link" href="/tag/nlp/" target="_self">#nlp</a>
    </span>
    
    <span class="prism-tag">
        <a class="no-link" href="/tag/tensorflow/" target="_self">#tensorflow</a>
    </span>
    
    <span class="prism-tag">
        <a class="no-link" href="/tag/gan/" target="_self">#gan</a>
    </span>
    
    <span class="prism-tag">
        <a class="no-link" href="/tag/lstm/" target="_self">#lstm</a>
    </span>
    
    <span class="prism-tag">
        <a class="no-link" href="/tag/language%20mode/" target="_self">#language mode</a>
    </span>
    
    <span class="prism-tag">
        <a class="no-link" href="/tag/rnn/" target="_self">#rnn</a>
    </span>
    
    <span class="prism-tag">
        <a class="no-link" href="/tag/heatmap/" target="_self">#heatmap</a>
    </span>
    
    <span class="prism-tag">
        <a class="no-link" href="/tag/dropout/" target="_self">#dropout</a>
    </span>
    
    <span class="prism-tag">
        <a class="no-link" href="/tag/machine%20learning/" target="_self">#machine learning</a>
    </span>
    
    
    
    <span>/</span>
    <span class="leancloud_visitors" id="/archives/Deep-Learning-with-Python-Notes-1/" data-flag-title="《Deep Learning with Python》笔记[1]"><span class="leancloud-visitors-count"></span> Views</span>
    
</div>
    </section>

    
<section id="prism__pagination" class="prism-pagination" class="col-md-8 offset-md-2">
    <ul>
        
        <li class="next">
            <a class="no-link" href="/archives/Deep-Learning-with-Python-Notes-2/" target="_self" title="《Deep Learning with Python》笔记[2]"><i class="fa fa-chevron-left" aria-hidden="true"></i>Newer</a>
        </li>
        
        
        <li class="prev">
            <a class="no-link" href="/archives/%E5%87%A0%E5%A4%A7%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95python%E5%AE%9E%E7%8E%B0/" target="_self" title="几大排序算法python实现">Older<i class="fa fa-chevron-right" aria-hidden="true"></i></a>
        </li>
        
    </ul>
</section>


    
    <script>
        var initValine = function() {
            new Valine({"enable": true, "el": "#vcomments", "appId": "7tP92LoqK2cggW61DvJmWBo0-gzGzoHsz", "appKey": "iQCtrtlr8eKrQllM03GMESMJ", "visitor": true, "recordIP": true});
        }

    </script>
    <script defer src='https://cdn.jsdelivr.net/npm/valine@1.3.10/dist/Valine.min.js' onload="initValine()"></script>
    <div class="prism-comment-section container" id="prism__comment">
        <div class="row">
            <div class="col-md-8 offset-md-2">
                <div id="vcomments"></div>
            </div>
        </div>
    </div>
    

</main>

            <footer id="prism__footer">
                <section>
                    <div>
                        <nav class="social-links">
                            <ul><li><a class="no-link" title="Twitter" href="https://twitter.com/walkerwzy" target="_blank" rel="noopener noreferrer nofollow"><i class="gi gi-twitter"></i></a></li><li><a class="no-link" title="GitHub" href="https://github.com/walkerwzy" target="_blank" rel="noopener noreferrer nofollow"><i class="gi gi-github"></i></a></li><li><a class="no-link" title="Weibo" href="https://weibo.com/1071696872" target="_blank" rel="noopener noreferrer nofollow"><i class="gi gi-weibo"></i></a></li></ul>
                        </nav>
                    </div>

                    <section id="prism__external_links">
                        <ul>
                            
                            <li>
                                <a class="no-link" target="_blank" href="https://github.com/AlanDecode/Maverick" rel="noopener noreferrer nofollow">Maverick</a>：🏄‍ Go My Own Way.
                                <span>|</span>
                            </li>
                            
                            <li>
                                <a class="no-link" target="_blank" href="https://www.imalan.cn" rel="noopener noreferrer nofollow">Triple NULL</a>：Home page for AlanDecode.
                                <span>|</span>
                            </li>
                            
                        </ul>
                    </section>

                    <div class="copyright">
                        <p class="copyright-text">
                            <span class="brand">walker's code blog</span>
                            <span>Copyright © 2022 AlanDecode</span>
                        </p>
                        <p class="copyright-text powered-by">
                            | Powered by <a href="https://github.com/AlanDecode/Maverick" class="no-link" target="_blank" rel="noopener noreferrer nofollow">Maverick</a> | Theme <a href="https://github.com/Reedo0910/Maverick-Theme-Prism" target="_blank" class="no-link" rel="noopener noreferrer nofollow">Prism</a>
                        </p>
                    </div>
                    <div class="footer-addon">
                        
                    </div>
                </section>
                <script>
                    var site_build_date = "2019-12-06T12:00+08:00"

                </script>
                <script src="https://cdn.jsdelivr.net/gh/wzywalker/wzywalker.github.io@main/assets/prism-efa8685153.js"></script>
            </footer>
        </div>
    </div>
    </div>

    <script src="https://cdn.jsdelivr.net/gh/wzywalker/wzywalker.github.io@main/assets/ExSearch/jquery.min.js"></script>
    <script src="https://cdn.jsdelivr.net/gh/wzywalker/wzywalker.github.io@main/assets/ExSearch/ExSearch-493cb9cd89.js"></script>

    <!--katex-->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/wzywalker/wzywalker.github.io@main/assets/katex.min.css">
    <script defer src="https://cdn.jsdelivr.net/gh/wzywalker/wzywalker.github.io@main/assets/katex.min.js"></script>
    <script>
        mathOpts = {
            delimiters: [
                { left: "$$", right: "$$", display: true },
                { left: "\\[", right: "\\]", display: true },
                { left: "$", right: "$", display: false },
                { left: "\\(", right: "\\)", display: false }
            ]
        };

    </script>
    <script defer src="https://cdn.jsdelivr.net/gh/wzywalker/wzywalker.github.io@main/assets/auto-render.min.js" onload="renderMathInElement(document.body, mathOpts);"></script>

    
</body>

</html>