<!DOCTYPE HTML>
<html lang="english">

<head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="renderer" content="webkit">
    <meta name="HandheldFriendly" content="true">
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
    <meta name="keywords" content="Maverick,AlanDecode,Galileo,blog" />
    <meta name="generator" content="Maverick 1.2.1" />
    <meta name="template" content="Prism" />
    <link rel="alternate" type="application/rss+xml" title="walker's code blog &raquo; RSS 2.0" href="/feed/index.xml" />
    <link rel="alternate" type="application/atom+xml" title="walker's code blog &raquo; ATOM 1.0" href="/feed/atom/index.xml" />
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/wzywalker/wzywalker.github.io@main/assets/prism-b9d78ff38a.css">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/wzywalker/wzywalker.github.io@main/assets/ExSearch/ExSearch-182e5a8869.css">
    <link href="https://fonts.googleapis.com/css?family=Fira+Code&display=swap" rel="stylesheet">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/font-awesome@4.7.0/css/font-awesome.min.css">
    <script>
        var ExSearchConfig = {
            root: "",
            api: "https://cdn.jsdelivr.net/gh/wzywalker/wzywalker.github.io@main/d69e93fb6d600dd3092b98eaebaa4bce.json"
        }

    </script>
    
<title>《Deep Learning with Python》笔记[6] - walker's code blog</title>
<meta name="author" content="walker" />
<meta name="description" content="Advanced deep-learning best practices" />
<meta property="og:title" content="《Deep Learning with Python》笔记[6] - walker's code blog" />
<meta property="og:description" content="Advanced deep-learning best practices" />
<meta property="og:site_name" content="walker's code blog" />
<meta property="og:type" content="article" />
<meta property="og:url" content="/archives/Deep-Learning-with-Python-Notes-6/" />
<meta property="og:image" content="" />
<meta property="article:published_time" content="2021-10-03T18:29:00-00.00" />
<meta name="twitter:title" content="《Deep Learning with Python》笔记[6] - walker's code blog" />
<meta name="twitter:description" content="Advanced deep-learning best practices" />
<meta name="twitter:card" content="summary" />
<meta name="twitter:image" content="" />


    
</head>

<body>
    <div class="container prism-container">
        <header class="prism-header" id="prism__header">
            <h1 class="text-uppercase brand"><a class="no-link" href="/" target="_self">walker's code blog</a></h1>
            <p>coder, reader</p>
            <nav class="prism-nav"><ul><li><a class="no-link text-uppercase " href="/" target="_self">Home</a></li><li><a class="no-link text-uppercase " href="/archives/" target="_self">Archives</a></li><li><a class="no-link text-uppercase " href="/about/" target="_self">About</a></li><li><a href="#" target="_self" class="search-form-input no-link text-uppercase">Search</a></li></ul></nav>
        </header>
        <div class="prism-wrapper" id="prism__wrapper">
            
<main>
    <section class="prism-section row" id="prism__content">
        <article class="yue col-md-8 offset-md-2">
            <h1 class="prism-post-title">《Deep Learning with Python》笔记[6]</h1>
            <div class="prism-post-time">
                <time class="text-uppercase">
                    October 03 2021
                </time>
            </div>
            <div class="prism-content-body">
                <h1>Advanced deep-learning best practices</h1>
<p>这一章是介绍了更多的网络（从keras的封装特性出发）结构和模块，以及batch normalization, model ensembling等知识。</p><h2>beyond Sequential model</h2>
<p>前面介绍的都是Sequential模型，就是一个接一个地layer前后堆叠，现实中有很多场景并不是一进一出的：</p><ol>
<li>multi-input model</li>
</ol>
<p>假设为二手衣物估价：</p><ul>
<li>格式化的元数据（品牌，性别，年龄，款式）: one-hot, dense</li>
<li>商品的文字描述：RNN or 1D convnet</li>
<li>图片展示：2D convnet</li>
<li>每个input用适合自己的网络做输出，然后合并起来作为一个input，回归一个价格</li>
</ul>
<ol start="2">
<li>multi-output model (multi-head)</li>
</ol>
<p>一般的检测器通常就是多头模型，因为既要回归对象类别，还要回归出对象的位置</p><ol start="3">
<li>graph-like model</li>
</ol>
<p>这个名字很好地形容了做深度学习时看别人的网络是什么样的方式：看图。现代的SOTA的网络往往既深且复杂，而网络结构画出来也不再是一条线或几个简单分支，这本书干脆把它们叫图形网络：<code>Inception</code>, <code>Residual</code></p><p>为了能架构这些复杂的网络，keras介绍了新的语法，先看看怎么重写<code>Sequential</code>:</p><div class="highlight"><pre><span></span><span class="n">seq_model</span> <span class="o">=</span> <span class="n">Sequential</span><span class="p">()</span>
<span class="n">seq_model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">,</span> <span class="n">input_shape</span><span class="o">=</span><span class="p">(</span><span class="mi">64</span><span class="p">,)))</span>
<span class="n">seq_model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">))</span>
<span class="n">seq_model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;softmax&#39;</span><span class="p">))</span>

<span class="c1"># 重写</span>
<span class="n">input_tensor</span> <span class="o">=</span> <span class="n">Input</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">64</span><span class="p">,))</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">)(</span><span class="n">input_tensor</span><span class="p">)</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>
<span class="n">output_tensor</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;softmax&#39;</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">Model</span><span class="p">(</span><span class="n">input_tensor</span><span class="p">,</span> <span class="n">output_tensor</span><span class="p">)</span>

<span class="n">model</span><span class="o">.</span><span class="n">summayr</span><span class="p">()</span>
</pre></div>
<p>我们自己实现过静态图，最终去执行的时候能从尾追溯到头，并从头来开始计算，这里也是一样的：</p><ol>
<li>input, output是Tensor类，所以有完整的层次信息</li>
<li>output往上追溯，最终溯到缺少一个input</li>
<li>这个input恰好也是Model的构造函数之一，闭环了。</li>
</ol>
<p>书里说的更简单，output是input不断transforming的结果。如果传一个没有这个关系的input进去，就会报错。</p><p><strong>demo</strong></p><p>用一个QA的例子来演示多输入（一个问句，一段资料），输出为答案在资料时的索引（简化为单个词，所以只有一个输出）</p><div class="highlight"><pre><span></span><span class="n">text_input</span> <span class="o">=</span> <span class="n">Input</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="kc">None</span><span class="p">,),</span> <span class="n">dtype</span><span class="o">=</span><span class="s1">&#39;int32&#39;</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;text&#39;</span><span class="p">)</span>
<span class="n">embedded_text</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">Embedding</span><span class="p">(</span>
    <span class="mi">64</span><span class="p">,</span> <span class="n">text_vocabulary_size</span><span class="p">)(</span><span class="n">text_input</span><span class="p">)</span>
<span class="n">encoded_text</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">LSTM</span><span class="p">(</span><span class="mi">32</span><span class="p">)(</span><span class="n">embedded_text</span><span class="p">)</span>  <span class="c1"># lstm 处理资讯</span>
<span class="n">question_input</span> <span class="o">=</span> <span class="n">Input</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="kc">None</span><span class="p">,),</span> <span class="n">dtype</span><span class="o">=</span><span class="s1">&#39;int32&#39;</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;question&#39;</span><span class="p">)</span>


<span class="n">embedded_question</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">Embedding</span><span class="p">(</span>
    <span class="mi">32</span><span class="p">,</span> <span class="n">question_vocabulary_size</span><span class="p">)(</span><span class="n">question_input</span><span class="p">)</span>
<span class="n">encoded_question</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">LSTM</span><span class="p">(</span><span class="mi">16</span><span class="p">)(</span><span class="n">embedded_question</span><span class="p">)</span> <span class="c1"># lstm 处理问句</span>

<span class="n">concatenated</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">concatenate</span><span class="p">([</span><span class="n">encoded_text</span><span class="p">,</span> <span class="n">encoded_question</span><span class="p">],</span> <span class="n">axis</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>  <span class="c1"># 竖向拼接（即不增加内容只增加数量）</span>
<span class="n">answer</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="n">answer_vocabulary_size</span><span class="p">,</span>
                      <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;softmax&#39;</span><span class="p">)(</span><span class="n">concatenated</span><span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">Model</span><span class="p">([</span><span class="n">text_input</span><span class="p">,</span> <span class="n">question_input</span><span class="p">],</span> <span class="n">answer</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">optimizer</span><span class="o">=</span><span class="s1">&#39;rmsprop&#39;</span><span class="p">,</span>
              <span class="n">loss</span><span class="o">=</span><span class="s1">&#39;categorical_crossentropy&#39;</span><span class="p">,</span>
              <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;acc&#39;</span><span class="p">])</span>
</pre></div>
<p>这里是把答案直接给回归出来了(one-hot)，如果是给出答案的首尾位置，那肯定只能用索引了。</p><p><strong>demo</strong></p><p>多头输出的：</p><div class="highlight"><pre><span></span><span class="c1"># 线性回归</span>
<span class="n">age_prediction</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;age&#39;</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>
<span class="c1"># 逻辑回归</span>
<span class="n">income_prediction</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="n">num_income_groups</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;softmax&#39;</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;income&#39;</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>
<span class="c1"># 二元逻辑回归</span>
<span class="n">gender_prediction</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;sigmoid&#39;</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;gender&#39;</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">Model</span><span class="p">(</span><span class="n">posts_input</span><span class="p">,</span>
              <span class="p">[</span><span class="n">age_prediction</span><span class="p">,</span> <span class="n">income_prediction</span><span class="p">,</span> <span class="n">gender_prediction</span><span class="p">])</span>
</pre></div>
<p>梯度回归要求loss是一个标量，keras提供了方法将三个loss加起来，同时为了量纲统一，还给了权重参数：</p><div class="highlight"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">optimizer</span><span class="o">=</span><span class="s1">&#39;rmsprop&#39;</span><span class="p">,</span>
<span class="n">loss</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;mse&#39;</span><span class="p">,</span> <span class="s1">&#39;categorical_crossentropy&#39;</span><span class="p">,</span> <span class="s1">&#39;binary_crossentropy&#39;</span><span class="p">],</span> <span class="n">loss_weights</span><span class="o">=</span><span class="p">[</span><span class="mf">0.25</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">10.</span><span class="p">])</span>
</pre></div>
<h2>Directed acyclic graphs of layers</h2>
<p>有向无环图。可以理解为最终不会回到出发点。</p><p>现在会介绍的是几个<code>Modules</code>，意思是可以把它当成一个layer，来构造你的网络/模型。</p><h3>Inception Modules</h3>
<ul>
<li>inspired by <code>network-in-network</code></li>
<li>对同一个输入做不同（层数/深度）的卷积（保证最终相同的下采样维度），最后合并为一个输出</li>
<li>因为卷积的深度不尽相同，学到的空间特征也有粗有细</li>
</ul>
<h3>Residual Connections</h3>
<ul>
<li>有些地方叫shortcut</li>
<li>用的是相加，不是concatenate, 如果形状变了，对earlier activation做linear transformation</li>
<li>解决<code>vanishing gradients</code> and <code>representational bottlenecks</code></li>
<li>adding residual connections to any model that has more than 10 layers is likely to be beneficial.</li>
</ul>
<p><strong>representational bottlenecks</strong></p><p>序列模型时，每一层的表示都来自于前一层，如果前一层很小，比如维度过低，那么携带的信息量也被压缩得很有限了，整个模型都会被这个“瓶颈”限制。比如音频信号处理，降维就是降频，比如到0-15kHz，但是下游任务也没法recover dropped frequencies了。所有的损失都是永久的。</p><p>Residual connections, by <code>reinjecting</code> earlier information downstream, partially solve this issue for deep-learning models.（又一次强调<code>reinject</code>）</p><h3>Lyaer weight sharihng</h3>
<p>在网络的不同位置用同一个layer，并且参数也相同。等于共享了相同的知识，相同的表示，以及是同时(simultaneously)训练的。</p><p>一个语义相似度的例子，输入是A和B还是B和A，是一样的（即可以互换）。架构网络的时候，用LSTM来处理句子，需要做两个LSTM吗？当然可以，但是也可以只做一个LSTM，分别喂入两个句子，合并两个输出来做分类。就是考虑到这种互换性，既然能互换，也就是这个layer也能应用另一个句子，因此就不必要再新建一个LSTM.</p><h3>Models as layers</h3>
<p>讲了两点：</p><ol>
<li>model也可以当layer使用</li>
<li>多处使用同一个model也是共享参数，如上一节。</li>
</ol>
<p>举了个双摄像头用以感知深度的例子，每个摄像头都用一个Xception网络提取特征，但是可以共用这个网络，因为拍的是同样的内容，只需要处理两个摄像头拍到的内容的差别就能学习到深度信息。因为希望是用同样的特征提取机制的。</p><p>都是蜻蜓点水。</p><h2>More Advanced</h2>
<h3>Batch Normalization</h3>
<ol>
<li>第一句话就是说为了让样本数据看起来<strong>更相似</strong>，说明这是初衷。</li>
<li>然后是能更好地泛化到未知数据（同样也是因为bn后就<strong>更相似</strong>了）</li>
<li>深度网络中每一层之后也需要做<ul>
<li>还有一个书里没讲到的原因，就是把值移到激活函数的梯度大的区域（比如0附近），否则过大过小的值在激活函数的曲线里都是几乎没有梯度的位置</li>
</ul>
</li>
<li>内部用的指数移动平均(<code>exponential moving average</code>)</li>
<li>一些层数非常深的网络必须用BN，像resnet 50, 101, 152, inception v3, xception等</li>
</ol>
<h3>Depthwise Separable Convolution</h3>
<p>之前的卷积，不管有多少个layer，都是放到矩阵里一次计算的，DSC把每一个layer拆开，单独做卷积（不共享参数），因为没有一个巨大的矩阵，变成了几个小矩阵乘法，参数量也大大变少了。</p><ol>
<li>对于小样本很有效</li>
<li>对于大规模数据集，它可以成为里面的固定结构的模块（它也是Xception的基础架构之一）</li>
</ol>
<blockquote>
<p>In the future, it’s likely that depthwise separable convolutions will <code>completely replace regular convolutions</code>, whether for 1D, 2D, or 3D applications, due to their higher representational efficiency.</p></blockquote>
<p>?!!</p><h3>Model ensembling</h3>
<ol>
<li>Ensembling consists of <strong>pooling together</strong> the predictions of a set of different models, to produce better predictions.</li>
<li>期望每一个<code>good model</code>拥有<code>part of the truth</code>(部分的真相)。盲人摸象的例子，没有哪个盲人拥有直接感知一头象的能力，机器学习可能就是这样一个盲人。</li>
<li>The key to making ensembling work is the <code>diversity</code> of the set of classifiers -&gt; 关键是要“多样性”。 <code>Diversity</code> is what makes ensembling work.</li>
<li>千万<strong>不要</strong>去ensembling同样的网络仅仅改变初始化而去train多次的结果。</li>
<li>比较好的实践有ensemble <code>tree-based</code> models(random forests, gradient-boosted trees) 和深度神经网络</li>
<li>以及<code>wide and deep</code> category of models, blending deep learning with shallow learning.</li>
</ol>
<p>同样是蜻蜓点水。</p>
            </div>
        </article>
        <div class="prism-post-meta col-md-8 offset-md-2">
    <span>walker</span>
    
    <span>/</span>
    <span>
        <a class="category no-link" href="/category/posts/" target="_self">
        posts
        </a>
    </span>
    
    
    <span>/</span>
    
    <span class="prism-tag">
        <a class="no-link" href="/tag/deep%20learning/" target="_self">#deep learning</a>
    </span>
    
    <span class="prism-tag">
        <a class="no-link" href="/tag/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/" target="_self">#深度学习</a>
    </span>
    
    <span class="prism-tag">
        <a class="no-link" href="/tag/keras/" target="_self">#keras</a>
    </span>
    
    <span class="prism-tag">
        <a class="no-link" href="/tag/cv/" target="_self">#cv</a>
    </span>
    
    <span class="prism-tag">
        <a class="no-link" href="/tag/nlp/" target="_self">#nlp</a>
    </span>
    
    <span class="prism-tag">
        <a class="no-link" href="/tag/tensorflow/" target="_self">#tensorflow</a>
    </span>
    
    <span class="prism-tag">
        <a class="no-link" href="/tag/gan/" target="_self">#gan</a>
    </span>
    
    <span class="prism-tag">
        <a class="no-link" href="/tag/lstm/" target="_self">#lstm</a>
    </span>
    
    <span class="prism-tag">
        <a class="no-link" href="/tag/language%20mode/" target="_self">#language mode</a>
    </span>
    
    <span class="prism-tag">
        <a class="no-link" href="/tag/rnn/" target="_self">#rnn</a>
    </span>
    
    <span class="prism-tag">
        <a class="no-link" href="/tag/heatmap/" target="_self">#heatmap</a>
    </span>
    
    <span class="prism-tag">
        <a class="no-link" href="/tag/dropout/" target="_self">#dropout</a>
    </span>
    
    <span class="prism-tag">
        <a class="no-link" href="/tag/machine%20learning/" target="_self">#machine learning</a>
    </span>
    
    
    
    <span>/</span>
    <span class="leancloud_visitors" id="/archives/Deep-Learning-with-Python-Notes-6/" data-flag-title="《Deep Learning with Python》笔记[6]"><span class="leancloud-visitors-count"></span> Views</span>
    
</div>
    </section>

    
<section id="prism__pagination" class="prism-pagination" class="col-md-8 offset-md-2">
    <ul>
        
        <li class="next">
            <a class="no-link" href="/archives/Deep-Learning-with-Python-Notes-7/" target="_self" title="《Deep Learning with Python》笔记[7]"><i class="fa fa-chevron-left" aria-hidden="true"></i>Newer</a>
        </li>
        
        
        <li class="prev">
            <a class="no-link" href="/archives/Deep-Learning-with-Python-Notes-5/" target="_self" title="《Deep Learning with Python》笔记[5]">Older<i class="fa fa-chevron-right" aria-hidden="true"></i></a>
        </li>
        
    </ul>
</section>


    
    <script>
        var initValine = function() {
            new Valine({"enable": true, "el": "#vcomments", "appId": "7tP92LoqK2cggW61DvJmWBo0-gzGzoHsz", "appKey": "iQCtrtlr8eKrQllM03GMESMJ", "visitor": true, "recordIP": true});
        }

    </script>
    <script defer src='https://cdn.jsdelivr.net/npm/valine@1.3.10/dist/Valine.min.js' onload="initValine()"></script>
    <div class="prism-comment-section container" id="prism__comment">
        <div class="row">
            <div class="col-md-8 offset-md-2">
                <div id="vcomments"></div>
            </div>
        </div>
    </div>
    

</main>

            <footer id="prism__footer">
                <section>
                    <div>
                        <nav class="social-links">
                            <ul><li><a class="no-link" title="Twitter" href="https://twitter.com/walkerwzy" target="_blank" rel="noopener noreferrer nofollow"><i class="gi gi-twitter"></i></a></li><li><a class="no-link" title="GitHub" href="https://github.com/walkerwzy" target="_blank" rel="noopener noreferrer nofollow"><i class="gi gi-github"></i></a></li><li><a class="no-link" title="Weibo" href="https://weibo.com/1071696872" target="_blank" rel="noopener noreferrer nofollow"><i class="gi gi-weibo"></i></a></li></ul>
                        </nav>
                    </div>

                    <section id="prism__external_links">
                        <ul>
                            
                            <li>
                                <a class="no-link" target="_blank" href="https://github.com/AlanDecode/Maverick" rel="noopener noreferrer nofollow">Maverick</a>：🏄‍ Go My Own Way.
                                <span>|</span>
                            </li>
                            
                            <li>
                                <a class="no-link" target="_blank" href="https://www.imalan.cn" rel="noopener noreferrer nofollow">Triple NULL</a>：Home page for AlanDecode.
                                <span>|</span>
                            </li>
                            
                        </ul>
                    </section>

                    <div class="copyright">
                        <p class="copyright-text">
                            <span class="brand">walker's code blog</span>
                            <span>Copyright © 2022 AlanDecode</span>
                        </p>
                        <p class="copyright-text powered-by">
                            | Powered by <a href="https://github.com/AlanDecode/Maverick" class="no-link" target="_blank" rel="noopener noreferrer nofollow">Maverick</a> | Theme <a href="https://github.com/Reedo0910/Maverick-Theme-Prism" target="_blank" class="no-link" rel="noopener noreferrer nofollow">Prism</a>
                        </p>
                    </div>
                    <div class="footer-addon">
                        
                    </div>
                </section>
                <script>
                    var site_build_date = "2019-12-06T12:00+08:00"

                </script>
                <script src="https://cdn.jsdelivr.net/gh/wzywalker/wzywalker.github.io@main/assets/prism-efa8685153.js"></script>
            </footer>
        </div>
    </div>
    </div>

    <script src="https://cdn.jsdelivr.net/gh/wzywalker/wzywalker.github.io@main/assets/ExSearch/jquery.min.js"></script>
    <script src="https://cdn.jsdelivr.net/gh/wzywalker/wzywalker.github.io@main/assets/ExSearch/ExSearch-493cb9cd89.js"></script>

    <!--katex-->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/wzywalker/wzywalker.github.io@main/assets/katex.min.css">
    <script defer src="https://cdn.jsdelivr.net/gh/wzywalker/wzywalker.github.io@main/assets/katex.min.js"></script>
    <script>
        mathOpts = {
            delimiters: [
                { left: "$$", right: "$$", display: true },
                { left: "\\[", right: "\\]", display: true },
                { left: "$", right: "$", display: false },
                { left: "\\(", right: "\\)", display: false }
            ]
        };

    </script>
    <script defer src="https://cdn.jsdelivr.net/gh/wzywalker/wzywalker.github.io@main/assets/auto-render.min.js" onload="renderMathInElement(document.body, mathOpts);"></script>

    
</body>

</html>